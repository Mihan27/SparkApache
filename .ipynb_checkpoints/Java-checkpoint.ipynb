{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-22T11:45:34.819708Z",
     "start_time": "2025-04-22T11:45:34.814252Z"
    }
   },
   "source": [
    "# Выполните эту ячейку для проверки версии Java\n",
    "import os\n",
    "print(os.environ.get('JAVA_HOME'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Java\\jdk1.8.0_301\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T11:42:48.544856Z",
     "start_time": "2025-04-22T11:42:48.536426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Настройка переменных окружения для Spark\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Проверка текущих настроек\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Current PATH:\", os.environ.get('PATH'))\n",
    "\n",
    "# Установка переменных окружения\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Если у вас Windows, пути могут выглядеть примерно так:\n",
    "# os.environ['JAVA_HOME'] = 'C:\\\\Program Files\\\\Java\\\\jdk1.8.0_xxx'\n",
    "# os.environ['SPARK_HOME'] = 'C:\\\\path\\\\to\\\\spark'\n",
    "\n",
    "print(\"PYSPARK_PYTHON:\", os.environ.get('PYSPARK_PYTHON'))\n",
    "print(\"PYSPARK_DRIVER_PYTHON:\", os.environ.get('PYSPARK_DRIVER_PYTHON'))"
   ],
   "id": "813a5dccdea72420",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]\n",
      "Current PATH: C:\\Users\\User\\PycharmProjects\\SparkApache\\.venv\\Scripts;c:\\Users\\User\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\dotnet\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\NVIDIA Corporation\\NVIDIA app\\NvDLISR;C:\\spark\\bin;C:\\hadoop\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\;C:\\tizen-studio\\tools\\ide\\bin;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\JetBrains\\PyCharm Community Edition 2024.1.1\\bin;;C:\\Users\\User\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\User\\.dotnet\\tools;c:\\Users\\User\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\Program Files\\Microsoft\\Web Platform Installer\\;C:\\Program Files (x86)\\Microsoft ASP.NET\\ASP.NET Web Pages\\v1.0\\;C:\\Program Files (x86)\\Windows Kits\\8.0\\Windows Performance Toolkit\\;C:\\Program Files\\Microsoft SQL Server\\110\\Tools\\Binn\\;C:\\Program Files\\PowerShell\\7\\;C:\\Windows\\system32\\config\\systemprofile\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\;C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Program Files\\JetBrains\\PyCharm 2024.3.3\\bin\n",
      "PYSPARK_PYTHON: C:\\Users\\User\\PycharmProjects\\SparkApache\\.venv\\Scripts\\python.exe\n",
      "PYSPARK_DRIVER_PYTHON: C:\\Users\\User\\PycharmProjects\\SparkApache\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T11:43:51.824634Z",
     "start_time": "2025-04-22T11:43:45.467799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Выполните эту команду в терминале (не в ячейке Jupyter)\n",
    "!pip uninstall -y pyspark\n",
    "!pip install pyspark==3.1.2  # Эта версия обычно стабильно работает"
   ],
   "id": "981b176c21dd1028",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyspark 3.5.5\n",
      "Uninstalling pyspark-3.5.5:\n",
      "  Successfully uninstalled pyspark-3.5.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T11:45:07.225758Z",
     "start_time": "2025-04-22T11:45:07.218624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Настройка Java для Spark\n",
    "import os\n",
    "\n",
    "# Укажите путь к JDK (для Windows)\n",
    "os.environ['JAVA_HOME'] = 'C:\\\\Program Files\\\\Java\\\\jdk1.8.0_301'  # Укажите правильный путь к вашей установке Java\n",
    "\n",
    "# Проверка\n",
    "print(\"JAVA_HOME:\", os.environ.get('JAVA_HOME'))\n",
    "\n",
    "# Если у вас нет Java, вам нужно установить JDK 8\n",
    "# Скачайте JDK 8 с официального сайта Oracle или используйте OpenJDK"
   ],
   "id": "8e895814615586f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME: C:\\Program Files\\Java\\jdk1.8.0_301\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T11:46:25.710571Z",
     "start_time": "2025-04-22T11:46:25.694354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Настройка Spark\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Путь к установленному Spark (для Windows)\n",
    "# Если у вас нет установленного Spark, укажите путь, куда вы хотите его установить\n",
    "os.environ['SPARK_HOME'] = 'C:\\\\spark'  # Измените на ваш путь, если Spark уже установлен\n",
    "\n",
    "# Добавление Spark в PATH\n",
    "if os.path.exists(os.environ['SPARK_HOME']):\n",
    "    spark_python = os.path.join(os.environ['SPARK_HOME'], 'python')\n",
    "    py4j_path = None\n",
    "\n",
    "    # Поиск py4j в директории\n",
    "    for item in os.listdir(os.path.join(spark_python, 'lib')):\n",
    "        if item.startswith('py4j'):\n",
    "            py4j_path = os.path.join(spark_python, 'lib', item)\n",
    "            break\n",
    "\n",
    "    if py4j_path:\n",
    "        sys.path.insert(0, spark_python)\n",
    "        sys.path.insert(0, py4j_path)\n",
    "        print(f\"Spark Python path добавлен: {spark_python}\")\n",
    "        print(f\"Py4J path добавлен: {py4j_path}\")\n",
    "    else:\n",
    "        print(\"Не найден py4j в директории Spark\")\n",
    "else:\n",
    "    print(f\"Директория SPARK_HOME не существует: {os.environ['SPARK_HOME']}\")\n",
    "    print(\"Возможно, вам нужно установить Spark или указать правильный путь\")\n",
    "\n",
    "# Проверка настроек\n",
    "print(\"SPARK_HOME:\", os.environ.get('SPARK_HOME'))"
   ],
   "id": "86ac99c64c94c6fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Python path добавлен: C:\\spark\\python\n",
      "Py4J path добавлен: C:\\spark\\python\\lib\\py4j-0.10.9.5-src.zip\n",
      "SPARK_HOME: C:\\spark\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-22T11:46:38.441179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Инициализация Spark\n",
    "try:\n",
    "    # Импортируем pyspark\n",
    "    import pyspark\n",
    "    from pyspark import SparkConf, SparkContext\n",
    "\n",
    "    # Проверяем, есть ли уже активный контекст\n",
    "    sc = SparkContext._active_spark_context\n",
    "    if sc:\n",
    "        print(\"Останавливаем существующий SparkContext\")\n",
    "        sc.stop()\n",
    "\n",
    "    # Создаем конфигурацию\n",
    "    conf = SparkConf()\n",
    "    conf.setMaster(\"local[*]\")  # Используем все доступные ядра\n",
    "    conf.setAppName(\"SparkTest\")\n",
    "\n",
    "    # Устанавливаем конфигурации для решения возможных проблем\n",
    "    conf.set(\"spark.driver.allowMultipleContexts\", \"true\")\n",
    "\n",
    "    # Создаем новый SparkContext\n",
    "    sc = SparkContext(conf=conf)\n",
    "    print(\"SparkContext успешно создан!\")\n",
    "    print(f\"Версия Spark: {sc.version}\")\n",
    "    print(f\"Master: {sc.master}\")\n",
    "    print(f\"AppName: {sc.appName}\")\n",
    "\n",
    "    # Выполняем простой тест\n",
    "    test_rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "    print(f\"Тестовый RDD создан, содержит {test_rdd.count()} элементов\")\n",
    "    print(f\"Сумма элементов: {test_rdd.sum()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при инициализации Spark: {str(e)}\")\n",
    "\n",
    "    # Рекомендации по устранению ошибок\n",
    "    if \"Java gateway process exited\" in str(e):\n",
    "        print(\"\\nРекомендация: Убедитесь, что Java установлена и JAVA_HOME правильно настроен\")\n",
    "    elif \"JavaPackage\" in str(e):\n",
    "        print(\"\\nРекомендация: Проблема с Py4J. Попробуйте переустановить PySpark\")\n",
    "        print(\"pip uninstall pyspark\")\n",
    "        print(\"pip install pyspark==3.1.2\")\n",
    "    elif \"socket.error\" in str(e) or \"Connection refused\" in str(e):\n",
    "        print(\"\\nРекомендация: Проблема с сетевым подключением к Spark\")\n",
    "    else:\n",
    "        print(\"\\nПопробуйте установить findspark:\")\n",
    "        print(\"pip install findspark\")\n",
    "        print(\"\\nИ инициализировать Spark с его помощью:\")\n",
    "        print(\"import findspark\")\n",
    "        print(\"findspark.init()\")"
   ],
   "id": "b85f176813bd7336",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
